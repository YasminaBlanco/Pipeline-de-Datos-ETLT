# M贸dulo Spark

Este m贸dulo contiene el n煤cleo de la l贸gica ETL (Extract, Transform, Load) y el entorno de procesamiento distribuido (Apache Spark). Es donde los datos se limpian, enriquecen y transforman de la Capa RAW a las capas Silver y Gold.

##  Contenido

* [capa_silver.py](capa_silver.py): Script ETL para transformar datos **RAW** (JSON/Parquet crudos) en la capa **Silver** (datos limpios, aplanados y estandarizados en S3).
* [capa_gold.py](capa_gold.py): Script ETL para transformar datos **Silver** en la capa **Gold** (datos agregados, enriquecidos con 铆ndices de potencial energ茅tico y listos para el an谩lisis de negocio).
* [Dockerfile](Dockerfile): Define el entorno del contenedor Spark, incluyendo Python, PySpark, y todas las dependencias necesarias.
* [docker-compose.yaml](docker-compose.yaml)
* `.env`: Variables de entorno para Spark (ej: memoria, n煤cleos, credenciales S3).
* [reporte.ipynb](reporte.ipynb): Script de Jupyter Notebook para generar reportes de resultados.

## 锔 Flujo ETL

### 1. Capa Silver (`capa_silver.py`)

**Funci贸n:** Limpieza y Estandarizaci贸n.
* Lee datos de m煤ltiples fuentes y formatos (ej: JSON hist贸rico, Parquet reciente) desde S3 (Bucket RAW).
* Desanida las estructuras complejas (e.g., `main`, `weather`, `coord`).
* Aplica transformaciones de tipo de dato y validaci贸n de calidad.
* Escribe los resultados en S3 (Bucket SILVER) en formato Parquet particionado.

### 2. Capa Gold (`capa_gold.py`)

**Funci贸n:** Agregaci贸n y An谩lisis.
* Lee los datos limpios de S3 (Bucket SILVER).
* **Enriquecimiento:** Calcula 铆ndices de potencial energ茅tico (WPI y SPI).
* **Agregaci贸n:** Crea dos tablas anal铆ticas principales:
    1.  **Resumen Diario:** Promedios y extremos por d铆a (clave para reporting).
    2.  **Patrones Horarios/Mensuales:** Patrones de potencial energ茅tico a lo largo del tiempo (clave para la optimizaci贸n de la red).
* Escribe los resultados en S3 (Bucket GOLD) en formato Parquet particionado.

## Ejecuci贸n de Pruebas

Estos scripts son ejecutados por Airflow, pero puedes probarlos directamente en el contenedor de Spark:

1.  **Ejecutar ETL Silver:**
    ```bash
    docker-compose exec spark-server python3 /app/capa_silver.py
    ```

2.  **Ejecutar ETL Gold:**
    ```bash
    docker-compose exec spark-server python3 /app/capa_gold.py